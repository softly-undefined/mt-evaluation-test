{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU and COMET basic testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "import comet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explore the CWMT datasets I found on Kaggle [here](https://www.kaggle.com/datasets/warmth/cwmt-data). \n",
    "\n",
    "The dataset contains a large quantity of information from several years of CWMT conferences (2008, 2009, 2011) as well as a number of other sources, though for the purposes of this exploration I will be limiting my observations to specificially Chinese -> English datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasource</th>\n",
       "      <th>domain</th>\n",
       "      <th>setid</th>\n",
       "      <th>srclang</th>\n",
       "      <th>trglang</th>\n",
       "      <th>src</th>\n",
       "      <th>ref1</th>\n",
       "      <th>ref2</th>\n",
       "      <th>ref3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cwmt2008</td>\n",
       "      <td>ce-news</td>\n",
       "      <td>zh_en_news_trans</td>\n",
       "      <td>zh</td>\n",
       "      <td>en</td>\n",
       "      <td>狭小的防震棚已经成为北川擂鼓镇农民张秀华（58岁）临时的家，而就在这个“家”的中央，悬挂了一...</td>\n",
       "      <td>A small narrow anti-earthquake tent became the...</td>\n",
       "      <td>The shockproof shed has become a temporary hom...</td>\n",
       "      <td>The narrow quakeproof shelter has become the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cwmt2008</td>\n",
       "      <td>ce-news</td>\n",
       "      <td>zh_en_news_trans</td>\n",
       "      <td>zh</td>\n",
       "      <td>en</td>\n",
       "      <td>画像中，中共中央总书记胡锦涛和国务院总理温家宝两人在绵阳机场紧紧握手，画像下有一行题字：“伟...</td>\n",
       "      <td>In this portrait, Hu Jintao, the General Secre...</td>\n",
       "      <td>The picture showed General Secretary of the Co...</td>\n",
       "      <td>Hu Jintao, the general secretary of the CPC Ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cwmt2008</td>\n",
       "      <td>ce-news</td>\n",
       "      <td>zh_en_news_trans</td>\n",
       "      <td>zh</td>\n",
       "      <td>en</td>\n",
       "      <td>5月16日，四川汶川大地震发生后的第四天，胡锦涛从北京飞抵四川绵竹机场，亲自指挥抗震救灾。</td>\n",
       "      <td>On May 16th, four days after the Wenchuan eart...</td>\n",
       "      <td>On May 16, the fourth day after the Wenchuan E...</td>\n",
       "      <td>On May 16, the 4th day following Sichuan Wench...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cwmt2008</td>\n",
       "      <td>ce-news</td>\n",
       "      <td>zh_en_news_trans</td>\n",
       "      <td>zh</td>\n",
       "      <td>en</td>\n",
       "      <td>地震后当天就飞到灾区指挥的温家宝到机场迎接，两人一见面，就在飞机前握手致意。</td>\n",
       "      <td>Wen Jiabao, who flew to the disaster area same...</td>\n",
       "      <td>Wen Jiabao, who has arrived at the disaster ar...</td>\n",
       "      <td>Wen Jiabao, who flew to the quake-hit areas an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cwmt2008</td>\n",
       "      <td>ce-news</td>\n",
       "      <td>zh_en_news_trans</td>\n",
       "      <td>zh</td>\n",
       "      <td>en</td>\n",
       "      <td>张秀华家挂的胡、温画像是经过电脑处理，原来画面的其他人员已经被掩盖，只有两个人握手的画面。</td>\n",
       "      <td>The portrait of Hu and Wen hung in Zhang Xiuhu...</td>\n",
       "      <td>The portrait of Hu and Wen hung in Zhang Xiuhu...</td>\n",
       "      <td>The figure of President Hu and Premier Wen hun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datasource   domain             setid srclang trglang   \n",
       "0   cwmt2008  ce-news  zh_en_news_trans      zh      en  \\\n",
       "1   cwmt2008  ce-news  zh_en_news_trans      zh      en   \n",
       "2   cwmt2008  ce-news  zh_en_news_trans      zh      en   \n",
       "3   cwmt2008  ce-news  zh_en_news_trans      zh      en   \n",
       "4   cwmt2008  ce-news  zh_en_news_trans      zh      en   \n",
       "\n",
       "                                                 src   \n",
       "0  狭小的防震棚已经成为北川擂鼓镇农民张秀华（58岁）临时的家，而就在这个“家”的中央，悬挂了一...  \\\n",
       "1  画像中，中共中央总书记胡锦涛和国务院总理温家宝两人在绵阳机场紧紧握手，画像下有一行题字：“伟...   \n",
       "2      5月16日，四川汶川大地震发生后的第四天，胡锦涛从北京飞抵四川绵竹机场，亲自指挥抗震救灾。   \n",
       "3             地震后当天就飞到灾区指挥的温家宝到机场迎接，两人一见面，就在飞机前握手致意。   \n",
       "4      张秀华家挂的胡、温画像是经过电脑处理，原来画面的其他人员已经被掩盖，只有两个人握手的画面。   \n",
       "\n",
       "                                                ref1   \n",
       "0  A small narrow anti-earthquake tent became the...  \\\n",
       "1  In this portrait, Hu Jintao, the General Secre...   \n",
       "2  On May 16th, four days after the Wenchuan eart...   \n",
       "3  Wen Jiabao, who flew to the disaster area same...   \n",
       "4  The portrait of Hu and Wen hung in Zhang Xiuhu...   \n",
       "\n",
       "                                                ref2   \n",
       "0  The shockproof shed has become a temporary hom...  \\\n",
       "1  The picture showed General Secretary of the Co...   \n",
       "2  On May 16, the fourth day after the Wenchuan E...   \n",
       "3  Wen Jiabao, who has arrived at the disaster ar...   \n",
       "4  The portrait of Hu and Wen hung in Zhang Xiuhu...   \n",
       "\n",
       "                                                ref3  \n",
       "0  The narrow quakeproof shelter has become the t...  \n",
       "1  Hu Jintao, the general secretary of the CPC Ce...  \n",
       "2  On May 16, the 4th day following Sichuan Wench...  \n",
       "3  Wen Jiabao, who flew to the quake-hit areas an...  \n",
       "4  The figure of President Hu and Premier Wen hun...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the datasets properly for manipulation\n",
    "df2008 = pd.read_csv(\"mt-dataset/cwmt2008_ce_news.tsv\", delimiter=\"\\t\")\n",
    "df2009 = pd.read_csv(\"mt-dataset/cwmt2009_ce_news.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "# drops the 4 rows between the two datasets missing a third reference\n",
    "df2008.dropna()\n",
    "df2009.dropna()\n",
    "\n",
    "df2008.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets I will be using are now properly imported, note that each source Chinese code has not one but three \"correct\" English reference translations.\n",
    "\n",
    "My goal with this project is to learn about the application of the BLEU and COMET MT evaluation metrics, and to do this I will be evaluating the two main LLMs I've been using for my [Classical Chinese machine translation interface](https://github.com/softly-undefined/classical-chinese-tool-v2) off of two baseline scores:\n",
    "\n",
    "1. A translation completed by Google Translate, a commonly accepted machine translation tool used widely\n",
    "2. An approved reference translation, calculating BLEU and COMET comparing ref1 as the MT-generated output to ref2 and ref3 as references (this may be up for change, I'm not the hugest fan of using a different amount of reference translations for this section compared to earlier ones)\n",
    "3. Potentially Apple Translate, to compare it's efficacy as well, although that is also potentially up for change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this [tutorial](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/) to learn about calculating BLEU scores.\n",
    "\n",
    "\n",
    "COMET- calculates sentence-by-sentence, when looking corpus-wide it is simply an average of the sentence level scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#example code to reference\n",
    "references = [[['this', 'is', 'a', 'test'], ['this', 'is', 'test']]]\n",
    "candidates = [['this', 'is', 'a', 'test']]\n",
    "score = corpus_bleu(references, candidates)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a references array for the 2008 dataset in a format acceptable to corpus_bleu\n",
    "\n",
    "df2008[['ref1', 'ref2', 'ref3']] = df2008[['ref1', 'ref2', 'ref3']].astype(str)\n",
    "references2008 = df2008[['ref1', 'ref2', 'ref3']].values.tolist()\n",
    "references2008 = [[sentence.split() for sentence in ref_group] for ref_group in references2008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a references array for the 2009 dataset in a format acceptable to corpus_bleu\n",
    "\n",
    "df2009[['ref1','ref2','ref3']] = df2009[['ref1','ref2','ref3']].astype(str)\n",
    "references2009 = df2009[['ref1','ref2','ref3']].values.tolist()\n",
    "references2009 = [[sentence.split() for sentence in ref_group] for ref_group in references2009]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Before Generating Translations\n",
    "\n",
    "Later on in this project I will be generating a large number of translations using the different models I have been testing, but I want to ensure that I properly understand how to use the evaluation metrics before spending the time/money creating the translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU Score Testing\n",
    "First I will use BLEU to generate scores for the ref1 columns of the 2008 data compared to the ref2 and ref3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the relevant data\n",
    "df_test = df2008\n",
    "\n",
    "# format references from ref2 and ref3 columns\n",
    "df_test[['ref2', 'ref3']] = df_test[['ref2', 'ref3']].astype(str)\n",
    "references_test = df_test[['ref2', 'ref3']].values.tolist()\n",
    "references_test = [[sentence.split() for sentence in ref_group] for ref_group in references_test]\n",
    "\n",
    "# format candidates from ref1 column\n",
    "df_test['ref1'] = df_test['ref1'].astype(str)\n",
    "candidates_test = df_test['ref1'].values.tolist()\n",
    "candidates_test = [sentence.split() for sentence in candidates_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2520605875656664\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references_test, candidates_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I repeated the process using ref2 and ref3 as the candidates resulting in values of 0.2377663462841575 and 0.2208567008054941 respectively. These scores seem to make sense comparing them to numbers from the [original BLEU paper](https://aclanthology.org/P02-1040.pdf)\n",
    "\n",
    "\n",
    "\n",
    "With the knowledge from the [original BLEU paper](https://aclanthology.org/P02-1040.pdf) it is clear that I should not compare BLEU scores based on different numbers of reference translations, so going forward I won't be using these translations to compare (though I may try testing my MT output on only 2 references to make it viable for comparison)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMET Score Testing\n",
    "\n",
    "Next I will test the COMET Metric using the same idea of ref1 compared to ref2 and ref3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Generation\n",
    "\n",
    "I won't be generating the sentences themselves in this notebook file, but I have in separate files within this project, storing the resulting data in two .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOpenAI = pd.read_csv(\"mtranslations/openai2008.csv\")\n",
    "dfAnthropic = pd.read_csv(\"mtranslations/anthropic2008.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMET Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
